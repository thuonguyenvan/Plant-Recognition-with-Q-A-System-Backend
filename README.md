# Plant Medicine RAG Backend - Project Complete!

## ğŸ‰ PROJECT OVERVIEW

Vietnamese Plant Medicine Q&A system vá»›i 3 flows:
- **Flow 1:** Image-only classification
- **Flow 2:** Image + Text Q&A vá»›i LLM routing
- **Flow 3:** Pure text RAG

## ğŸ—ï¸ ARCHITECTURE

```
Frontend (Streamlit)
        â†“
FastAPI Backend
        â†“
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                       â”‚
CV API          OG-RAG HyperGraph
(Image)         (Supabase + pgvector)
                       â†“
               Vietnamese Embeddings
               (AITeamVN, 1024-dim)
                       â†“
                  MegLLM API
              (OpenAI-compatible)
```

## âœ… IMPLEMENTED FEATURES

### Core Services
- âœ… Vietnamese embedding service (AITeamVN/Vietnamese_Embedding)
- âœ… Supabase vector database (9,954 hypernodes)
- âœ… CV API client (plant classification)
- âœ… MegLLM client (OpenAI SDK)
- âœ… OG-RAG query engine

### Data Processing
- âœ… JSON-LD loader (1,305 plants)
- âœ… Key normalizer (80+ mappings)
- âœ… Value chunker (250 tokens, sentence-level)
- âœ… Ontology flattener (7,417 facts)

### Flows
- âœ… Flow 1: Top-5 predictions + summaries
- âœ… Flow 2: LLM routing + full plant context
- âœ… Flow 3: Pure RAG with sources

### API
- âœ… FastAPI with CORS
- âœ… 8 endpoints (classify, detail, ask, health)
- âœ… File upload + URL support

## ğŸ“Š DATABASE STATS

| Metric | Value |
|--------|-------|
| Plants | 1,305 |
| Facts | 7,417 |
| HyperNodes | 9,954 |
| Embedding dim | 1024 |
| Vector search | âœ… Working |

## ğŸš€ QUICK START

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Setup .env
```bash
SUPABASE_URL=your_url
SUPABASE_ANON_KEY=your_key
MEGLLM_API_KEY=your_key
```

### 3. Run API
```bash
python main.py
# or
uvicorn main:app --reload
```

### 4. Test Endpoints
```bash
# Health check
curl http://localhost:8000/health

# Flow 3 (RAG)
curl -X POST http://localhost:8000/api/flow3/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "CÃ¢y nÃ o chá»¯a ho?", "top_k": 5}'
```

## ğŸ“ PROJECT STRUCTURE

```
RAG_BACKEND/
â”œâ”€â”€ main.py              # FastAPI app
â”œâ”€â”€ config.py            # Settings
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ .env                # Credentials
â”‚
â”œâ”€â”€ api/                # (placeholder)
â”œâ”€â”€ services/           # Core services
â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”œâ”€â”€ vector_db_service.py
â”‚   â”œâ”€â”€ cv_api_client.py
â”‚   â”œâ”€â”€ llm_client.py
â”‚   â”œâ”€â”€ ograg_engine.py
â”‚   â”œâ”€â”€ flow1_service.py
â”‚   â”œâ”€â”€ flow2_service.py
â”‚   â””â”€â”€ flow3_service.py
â”‚
â”œâ”€â”€ utils/              # Utilities
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ key_normalizer.py
â”‚   â””â”€â”€ chunker.py
â”‚
â”œâ”€â”€ scripts/            # Data processing
â”‚   â”œâ”€â”€ flatten_ontology.py
â”‚   â”œâ”€â”€ build_hypergraph.py
â”‚   â”œâ”€â”€ import_embeddings.py
â”‚   â””â”€â”€ clean_duplicates.py
â”‚
â”œâ”€â”€ tests/              # Tests
â”‚   â”œâ”€â”€ test_connection.py
â”‚   â””â”€â”€ test_hypergraph.py
â”‚
â””â”€â”€ data/               # JSON-LD files
    â””â”€â”€ ontology_node_*.jsonld
```

## ğŸ”§ CONFIGURATION

### config.py
- Supabase credentials
- MegLLM API key
- CV API endpoint
- Model settings

### Vector Search Optimization
- Default top_k: 10 (reduced for performance)
- Threshold: 0.4 (lowered from 0.5)
- Retry logic: 2 attempts with adaptive top_k
- Timeout: 120s

## ğŸ“ API ENDPOINTS

### Flow 1: Image Classification
- `POST /api/flow1/classify` - Upload image
- `POST /api/flow1/classify-url` - Image URL
- `GET /api/flow1/detail/{class_name}` - Plant details

### Flow 2: Image + Text Q&A
- `POST /api/flow2/ask` - Upload + question
- `POST /api/flow2/ask-url` - URL + question

### Flow 3: Pure RAG
- `POST /api/flow3/ask` - Text question

### System
- `GET /` - Basic health
- `GET /health` - Detailed health

## âš ï¸ KNOWN LIMITATIONS

1. **Supabase Free Tier:**
   - Memory limit: 32MB (can't rebuild indexes)
   - Statement timeout (handled with retry)

2. **Vector Search:**
   - Works but requires retry logic
   - Optimized with reduced top_k

3. **MegLLM:**
   - Using OpenAI-compatible endpoint
   - Model: openai-gpt-oss-120b

## ğŸ¯ NEXT STEPS (Optional)

1. **Streamlit Demo** - Visual UI for all 3 flows
2. **ChromaDB Migration** - Alternative to Supabase (no timeout)
3. **Caching** - Redis for frequent queries
4. **Batch Processing** - Background jobs for embeddings
5. **Monitoring** - Logging + metrics

## ğŸ“š DEPENDENCIES

```
fastapi
uvicorn
python-multipart
sentence-transformers
torch
supabase
python-dotenv
pydantic-settings
httpx
openai
tqdm
numpy
```

## ğŸ¤ INTEGRATION EXAMPLES

### Python
```python
import requests

# Flow 3 RAG
response = requests.post(
    "http://localhost:8000/api/flow3/ask",
    json={"question": "SÃ¢m cau cÃ³ tÃ¡c dá»¥ng gÃ¬?"}
)
print(response.json())
```

### cURL
```bash
curl -X POST http://localhost:8000/api/flow3/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "CÃ¢y nÃ o trá»‹ ho?"}'
```

## âœ¨ HIGHLIGHTS

- âœ… **Vector search working** vá»›i retry mechanism
- âœ… **9,954 nodes indexed** trong Supabase
- âœ… **OG-RAG hypergraph** fully functional
- âœ… **3 complete flows** implemented
- âœ… **Production-ready API** with error handling
- âœ… **OpenAI-compatible LLM** integration

---

**Status:** âœ… COMPLETE & READY FOR DEMO
**Time:** ~4 hours from start to finish  
**Next:** Build Streamlit UI or test with real queries!
